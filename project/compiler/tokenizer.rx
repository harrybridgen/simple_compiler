import compiler.grammar;
import std.char;

MAX_TOKENS := 16;

struct Lexer {
    tokens := [MAX_TOKENS]
    len = 0;
}

func tokenize(src) {
    r := struct Lexer;

    i = 0;
    di ::= i + 1;

    loop {
        if i >= src { break; }

        c := src[i];

        if is_space(c) {
            i = di;
        }
        else if is_digit(c) {
            val = digit_to_int(c);
            i = di;

            loop {
                if i >= src { break; }
                if !is_digit(src[i]) { break; }
                val = val * 10 + (digit_to_int(src[i]));
                i = di;
            }
            t := tokenNum(TK_Number, r, val)
        }
        else if c == '+' {
            t := tokenOper(TK_Add, r);
            i = di;
        }
        else if c == '-' {
            t := tokenOper(TK_Sub, r);
            i = di;
        }

        else {
            println "error: unknown character";
            break;
        }
    }

    return r;
}

func print_token(t) {
    if t.kind == TK_Number {
        println t.ival;
    }
    else if t.kind == TK_Add {
        println "+";
    }
    else if t.kind == TK_Sub {
        println "-";
    }
    else {
        println "Could not print symbol";
    }
}